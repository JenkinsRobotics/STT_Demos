
# **üîß Engineering Log 005 ‚Äì Whisper MLX STT Demo**

  

**Date:** 2025-06-26

**Component:** Whisper MLX (Apple Silicon‚ÄìOptimized STT)

**Status:** ‚úÖ Completed

**Environment:** Python 3.11.9 (via pyenv), macOS (M1 Max)

---

## **üß† Overview**

  

This experiment evaluated [mlx-whisper](https://pypi.org/project/mlx-whisper/0.4.1/), a fully local, Apple Silicon‚Äìoptimized implementation of Whisper using [MLX](https://github.com/ml-explore/mlx), designed to run fast inference via the Metal backend. Goals:

- Test real-time batch transcription of a known WAV file (jfk_moon.wav)
    
- Validate GPU (Metal) usage via MLX
    
- Measure latency vs. pywhispercpp and whisper.cpp
    
- Confirm model compatibility and segment-level timestamps
    

---

## **üì¶ Installation**

```
pip install mlx mlx-whisper soundfile
```

> üìå Requires Python ‚â•3.9 running natively on Apple Silicon (M1/M2/M3).

> ‚úÖ libsndfile must be available (typically preinstalled or installable via Homebrew).

---

## **üóÇÔ∏è Folder Structure**

```
whisper_MLX/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ whisper-medium/
‚îú‚îÄ‚îÄ samples/
‚îÇ   ‚îî‚îÄ‚îÄ jfk_moon.wav
‚îú‚îÄ‚îÄ transcribe_file.py
```

---

## **üìÑ Script:**¬†

## **transcribe_file.py**

```
import os
import soundfile as sf
import mlx.core as mx
import mlx_whisper
import time
from datetime import timedelta

def format_time(seconds: float) -> str:
    return str(timedelta(seconds=int(seconds)))

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(BASE_DIR, "models", "whisper-medium")
AUDIO_FILE = os.path.join(BASE_DIR, "samples", "jfk_moon.wav")

print(f"MLX device: {mx.default_device()}")

if not os.path.exists(AUDIO_FILE):
    raise FileNotFoundError(f"Audio file not found: {AUDIO_FILE}")

audio, sr = sf.read(AUDIO_FILE)
if sr != 16000:
    raise ValueError(f"Expected 16kHz sample rate, got {sr}")
if audio.ndim > 1:
    print("Converting stereo to mono...")
    audio = audio[:, 0]

print(f"Transcribing using model: {MODEL_PATH}")
start = time.time()

result = mlx_whisper.transcribe(audio, path_or_hf_repo=MODEL_PATH)

elapsed = time.time() - start
print(f"\nTranscription completed in {elapsed:.2f} seconds\n")

print("Full Transcript:")
print(result["text"].strip())

if "segments" in result:
    print("\nSegment Timestamps:")
    for seg in result["segments"]:
        start = format_time(seg["start"])
        end = format_time(seg["end"])
        print(f"[{start} ‚Äì {end}] {seg['text'].strip()}")
```

---

## **üìà Performance**

  

**Test Audio:** jfk_moon.wav (26s, 16kHz mono)

|**Model**|**Time Elapsed**|**Device**|**Transcript Quality**|**Notes**|
|---|---|---|---|---|
|whisper-medium (MLX)|**1.62s**|Device(gpu, 0)|‚úÖ High|Fastest clean result so far|

---

## **üß™ Observations**

- ‚úÖ **GPU detected:** mlx.core.default_device() ‚Üí Device(gpu, 0)
    
- ‚úÖ **Fast batch inference**: ~1.6s on whisper-medium model
    
- ‚úÖ **Includes segment timestamps**
    
- ‚úÖ **Simple Python API** ‚Äì usable in pipelines or UIs
    
- ‚ö†Ô∏è **No streaming API yet** ‚Äì not suitable for real-time UI updates
    
- üîá **Silent logs** ‚Äì ideal for clean CLI or backend service use
    

---

## **üì• Model Download**

  

Via Hugging Face:

```
git clone https://huggingface.co/ml-explore/whisper-medium models/whisper-medium
```

This places model weights into a local folder accessible by mlx_whisper.

---

## **üß© Integration Tips**

- Can be used in PySide or CLI apps for low-latency offline transcription
    
- Transcribe one .wav at a time; not designed for token-wise streaming
    
- Combine with VAD or mic chunker if used in session-based STT applications
    
- Output JSON result includes segments, text, and timing metadata
    

---

## **‚úÖ Summary**

  

Whisper MLX is an **Apple-native**, GPU-accelerated implementation of Whisper that performs fast, accurate STT on macOS devices without needing external runtime engines or PyTorch. It‚Äôs ideal for local batch transcription, embedded assistants, and production setups where simplicity and performance matter.

  

> ‚ö†Ô∏è Not yet suitable for **real-time transcription GUIs**, but excellent for offline processing or command-triggered use cases.

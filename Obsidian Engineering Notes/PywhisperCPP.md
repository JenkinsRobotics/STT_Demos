# **Engineering Note: Whisper STT â€“ Python Binding with pywhispercpp**

  

**Project Name:** Whisper STT â€“ Python Binding with pywhispercpp
**Log ID:** 005
**Date:** 2025-06-25
**Status:** âœ… Completed

**Tags:** #STT #Whisper #WhisperCpp #Python #OfflineAI #MetalGPU #RealTime

---

### **ğŸ”§ Objective**

  

Evaluate and integrate the pywhispercpp Python wrapper for Whisper.cpp to enable fast, offline speech-to-text inference with Metal GPU acceleration on Apple Silicon. Assess viability for use in local real-time transcription pipelines and GUI-based STT tools.

---

### **ğŸ—‚ï¸ Summary**

|**Item**|**Details**|
|---|---|
|**Wrapper Used**|[pywhispercpp](https://github.com/absadiki/pywhispercpp)|
|**Platform**|macOS (Apple Silicon â€“ M1 Max)|
|**Python Version**|3.11.9|
|**GPU Acceleration**|âœ… Metal (confirmed in logs)|
|**Transcription Mode**|âœ… File inputğŸŸ¡ Real-time preview via audio queues|
|**Use Case**|Offline, low-latency STT in GUI or CLI tools|

---

### **ğŸ“¦ Installation**

```
pip uninstall whispercpp  # If previously installed
pip install pywhispercpp
```

No manual CMake, model download, or whisper.cpp build steps required â€” all handled via pip.

---

### **ğŸ“ Model Handling**

  

Models are automatically downloaded to:

```
~/Library/Application Support/pywhispercpp/models/
```

Supported models include:

- tiny, tiny.en
    
- base, base.en
    
- small, medium, large
    

---

### **ğŸ§ª Example Usage (Batch)**

```
from pywhispercpp.model import Model

model = Model(model_name="tiny.en")
text = model.transcribe("jfk_moon.wav")
print(text)
```

âœ… Output includes progress updates and confirms Metal GPU usage:

```
whisper_default_buffer_type: using device Metal (Apple M1 Max)
Progress: 100%
```

---

### **ğŸ–¥ GUI Integration**

  

A real-time GUI app was implemented using pywhispercpp, PySide6, and sounddevice. Key features:

- Mic input + volume meter
    
- Partial + final transcript display
    
- 3-second and 10-second rolling audio buffers
    
- Export transcript to .txt
    
- Streamed inference with overlap de-duplication logic
    

  

> âš ï¸ PySide6 UI updates must be handled in the main thread to avoid segmentation faults or QTextDocument errors.

---

### **ğŸ§  Real-Time Observations**

- While not truly token-streaming, pywhispercpp handles 3s and 10s rolling window buffers well.
    
- Best performance achieved by segmenting audio and extracting the center portion (50%) to append final text.
    
- For long sessions (20+ mins), stable behavior was maintained using memory-efficient buffers.
    
- Duplication filtering was partially implemented; LLM-based cleanup was proposed for future improvement.
    

---

### **ğŸ—‘ï¸ Legacy Cleanup**

  

You can safely delete if transitioning to pywhispercpp fully:

- whisper.cpp/
    
- models/ (unless manually managed for Whisper.cpp CLI)
    

---

### **âœ… Summary**

  

pywhispercpp is a powerful and easy-to-integrate wrapper for Whisper.cpp. It offers:

- ğŸ§  High transcription quality
    
- âš¡ Fast Metal-accelerated decoding on Apple Silicon
    
- ğŸ–¥ GUI-ready for PySide6 integration
    
- ğŸ“¡ Partial support for real-time streaming via chunked buffers
    

  

It is now a top candidate for offline STT systems where Whisper accuracy and responsiveness are required without cloud dependencies.

# **Engineering Note: FasterWhisper STT GUI Test**

  

**Project Name:**Â **Whisper STT Standalone GUI Test**
**Focus:**Â Streaming Speech-to-Text Evaluation
**Log:**Â 004
**Date:**Â 2025-06-24
**Status:**Â âœ… Completed

  

> #AIAudio #STT #Whisper #FasterWhisper

---

### **ğŸ¯ Objective**
 

Evaluate the performance and responsiveness of the **faster-whisper** engine (based on CTranslate2) within a real-time PySide6 GUI STT app. Assess its viability for offline, always-on speech agents and compare its usability and accuracy to Whisper.cpp and Vosk.

---

### **ğŸ“¦ Model Details**

- **Library:** [faster-whisper](https://github.com/guillaumekln/faster-whisper)    
- **Engine:** CTranslate2
- **License:** MIT
- **Model Used (default):** tiny.en (153 MB)
- **Model Source:** [Hugging Face](https://huggingface.co/Systran/faster-whisper-tiny.en)

---

### **ğŸ“ Model Setup**

  

A script is provided to download all models:

```
python download_all_fasterwhisper_models.py
```

Example structure:

```
project/
â”œâ”€â”€ whisperstt_demo.py
â”œâ”€â”€ download_all_fasterwhisper_models.py
â””â”€â”€ models/
    â”œâ”€â”€ tiny.en/
    â”œâ”€â”€ base/
    â””â”€â”€ medium/
```

Each folder contains:

- model.bin
    
- config.json
    
- tokenizer.json
    
- vocabulary.txt
    

---

### **ğŸ§  Available Models**

|**Model**|**Size**|**Notes**|
|---|---|---|
|tiny|~75 MB|Fastest, lowest accuracy|
|tiny.en|~153 MB|English-only, better accuracy|
|base|~142 MB|Multi-language|
|medium|~1.5 GB|High accuracy|
|large-v3|~2.9 GB|Best accuracy, slowest|

âœ… **Recommended for real-time CPU:** tiny.en or base

---

### **ğŸ›  Installation**

```
pip install faster-whisper sounddevice numpy scipy PySide6
```

Optional (for VAD):

```
pip install onnxruntime
```

---

### **âš™ï¸ Backend Config (macOS)**

|**Device**|**Backend**|**Supported**|**Notes**|
|---|---|---|---|
|CPU|int8/f32|âœ… Yes|Works well with compute_type="int8"|
|GPU|Metal (MPS)|âŒ No|Not supported yet|

---

### **ğŸ–¥ GUI Features**

- Real-time microphone input
    
- Automatic chunking (~1.5s)
    
- Volume meter
    
- Display of current + final transcript
    
- Transcript export to .txt
    

---

### **ğŸ“ˆ Performance (Tiny.en + CPU)**

|**Metric**|**Value**|
|---|---|
|Chunk size|~1.5s|
|Latency|~1.2â€“1.6s per chunk|
|Accuracy|High|
|CPU Usage|Moderate|
|Real-time|ğŸŸ¡ Partial (delayed)|

---

### **ğŸš« Limitations**

- Not true token-by-token streaming
    
- Each audio chunk is processed as a full segment
    
- GUI may delay under high load without threading optimizations
    
- MPS / GPU acceleration not available on macOS yet
    

---

### **âœ… Strengths**

- Excellent accuracy with tiny.en
    
- Fast CPU-only inference
    
- Simple to integrate into PySide6 GUI
    
- Good for offline agents or robotic use cases
    

---

### **ğŸ§ª Future Work**

- Implement true streaming (e.g., rolling window buffer logic)
    
- Add Whisper.cpp or MLX for GPU acceleration
    
- Add LLM-based transcript cleanup post-processor
    
- Improve overlap-debouncing and phrase deduplication
    
- Enable real-time word-level alignment (if possible)
    

---

### **ğŸ§¾ Summary**

  

FasterWhisper delivers accurate STT via an optimized CTranslate2 backend. While not a true token streamer, it performs well in low-latency offline GUI scenarios. It is an excellent balance of accuracy and speed on CPU-only macOS systems.

  